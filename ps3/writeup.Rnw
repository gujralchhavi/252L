\documentclass{article}

\usepackage{amsmath}
\usepackage{lineno}
\usepackage{enumitem}
\usepackage{float}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}

\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}

\linenumbers

\title{Problem Set 3}
\author{Carrie Kathlyn Townley Flores, Filipe Recch, Kaylee Tuggle Matheny, \\ Klint Kanopka, Kritphong Mongkhonvanit \\ EDUC 252L}

<<echo=FALSE,warning=FALSE,message=FALSE,error=FALSE>>=
knitr::opts_chunk$set(cache=TRUE, echo = FALSE, fig.pos="H",fig.height=4, fig.width=8, fig.align = "center")
library(mirt)
library(psych)
require('WrightMap')
@

\begin{document}
\maketitle

\section*{Shortish Answer}
\begin{enumerate}

\item Suppose that we have a test scaled with the Rasch model whose first 3 items have known difficulties -1, 0, and 1.5. An examinee with ability theta got the first item right, the second item right, and the third item wrong. Can you write the likelihood of observing this sequence of item responses as a function of theta?

The likelihood of getting each item right in the Rash model is given by:

$$ \frac{\epsilon^{\theta - b}}{1+\epsilon^{\theta - b}} $$ 

Therefore, each item's likelihood, considering its difficulty is as follows:
Item dif -1: $ \frac{\epsilon^{\theta + 1}}{1+\epsilon^{\theta + 1}} $ \\
Item dif 0: $ \frac{\epsilon^{\theta - 0}}{1+\epsilon^{\theta - 0}} $ \\
Item dif 1.5: $ 1 - \frac{\epsilon^{\theta - 1.5}}{1+\epsilon^{\theta - 1.5}} $ 

The chance of getting the specific sequence is the product of the probabilities of each item in the sequence. Hence, a 1-1-0 sequence has the probability equal to:

$$ \left(\frac{\epsilon^{\theta + 1}}{1+\epsilon^{\theta + 1}}\right) \times \left(\frac{\epsilon^{\theta - 0}}{1+\epsilon^{\theta - 0}} \right) \times \left(1 - \frac{\epsilon^{\theta - 1.5}}{1+\epsilon^{\theta - 1.5}} \right) $$

\item Can you plot this as a function of theta?

<<graph1, fig.cap="Probabilities as a function of theta">>=
th<-seq(-3,3,length.out=1000)
p<-function(b) exp(th-b)/(1+exp(th-b))

plot(th,p(-1)*p(0)*(1-p(1.5)), ylim = c(0,.4), type = "n", xlab = expression(theta))
lines(th,p(-1)*p(0)*(1-p(1.5)), ylim = c(0,.4), lwd= 3)
@

\item If theta=0.5, what is the likelihood of that response sequence?

<<echo=TRUE>>=
th<-0.5
p<-function(b) exp(th-b)/(1+exp(th-b))
round(p(-1)*p(0)*(1-p(1.5)),3)
@

\item If theta=0.5, what is the most likely response sequence given the known item difficulties? 

The probabilities of getting each item right is \Sexpr{round(p(-1),2)}, \Sexpr{round(p(0),2)} and \Sexpr{round(p(1.5),2)}, respectively for item difficulties of -1, 0, 1.5. Therefore, the most likely sequence is exactly 1-1-0.

\item At what value of theta does a response sequence of 1-1-0 (that is: they got the first and second items right and the third item wrong) become more likely than a response sequence of 1-0-0?

<<graph2, fig.cap="Probabilities as a function of theta">>=
th<-seq(-3,3,length.out=1000)
plot(th,p(-1)*p(0)*(1-p(1.5)), ylim = c(0,.4), type = "n", xlab = expression(theta))
lines(th,p(-1)*p(0)*(1-p(1.5)), ylim = c(0,.4), lwd = 3)
lines(th,p(-1)*(1-p(0))*(1-p(1.5)), lwd = 3, lty = 2)
abline(v=0)
@

Considering that the only difference between the two sequeces is either the student got the second item right or wrong and that this specific item has difficulty $b = 0$, then getting 1-1-0 becames more likely at $\theta = 0$.

\item Returning to questions 1 and 2, can you plot the ``test information" as a function of theta (see Eqn 2-6 in Lord). 

To get the test information we need to sum over the all items information. In order to get the item information, we need to take the derivative with respect to $\theta$ of the probability of getting each item right. The ``test information" is as follows:

$$ \displaystyle\sum \ddfrac{\left(\ddfrac{\epsilon^{\theta+b}}{\left(\epsilon^{\theta}+\epsilon^{b}\right)^2}\right)^2}{\left(\ddfrac{\epsilon^{\theta-b}}{1+ \epsilon^{\theta-b}}\right) \left(1 - \ddfrac{\epsilon^{\theta-b}}{1 + \epsilon^{\theta-b}}\right)} $$

Using this formula, we get figure \ref{fig:graph3}.

<<graph3, fig.cap="Test information curve">>=
# derivative of p
pp <- function(b) {
	exp(th+b)/(exp(b)+exp(th))^2
}
item_info <- function(b) {
	pp(b)^2/(p(b)*(1-p(b)))
}

item_info_points <- item_info(-1)+item_info(0)+item_info(1.5)
plot(th, item_info_points, type="n", xlab = expression(theta))
lines(th, item_info_points, lwd=3)
@

\item Where is the function in \#6 maximized? What do you think this implies? 

In this case, the maximum is at 0.027.  This, in a sense, represents the ability score that the the test is best at measuring.  More specifically, the test is good at discerning between abilities near this value and worse at discerning between abilities far from this value.

<<>>=
th[which(item_info_points==max(item_info_points))]
@

Since the value is very close to zero, it implies that $\theta$ will be
estimated most precisely when it is close to zero.

\item For an item response dataset of your choosing, consider the relationship between theta and the SE across the three IRT models for dichotomous items. How much of a difference does the choice of model have on the size of the error estimate?

First consider plots of the standard error vs. ability for the three IRT models, generated from the emp-rasch.txt data set used in lab:

<<echo=FASLE, results='hide', fig.cap="Standard error as a function of ability">>=
respk<-read.table("emp-rasch.txt",header=FALSE)

#generate models
modk1<-mirt(respk,1,itemtype="Rasch")
modk2<-mirt(respk,1,itemtype="2PL")
modk3<-mirt(respk,1,itemtype="3PL")

#estimate and sort abilities
fscores(modk1,full.scores.SE=TRUE)->thk1
th1[order(thk1[,1]),]->thk1
fscores(modk2,full.scores.SE=TRUE)->thk2
th2[order(thk2[,1]),]->thk2
fscores(modk3,full.scores.SE=TRUE)->thk3
th3[order(thk3[,1]),]->thk3

#generate plots
par(mfrow=c(3,1))
plot(jitter(thk1),xlab="theta",ylab="se", main='Rasch',xlim=c(-4,4), ylim=c(0.175,0.625))
plot(jitter(thk2),xlab="theta",ylab="se",main='2PL',xlim=c(-4,4), ylim=c(0.175,0.625))
plot(jitter(thk3),xlab="theta",ylab="se",main='3PL',xlim=c(-4,4), ylim=c(0.175,0.625))
@

As you increase the number of estimated parameters in a model, the standard error, as a whole, decreases.  One interesting feature is the area of lowest standard error shifts between the models.  This is likely due to the change in estimated item difficulties as the models increase in complexity.  The reduction in standard error for more complex models makes sense, because the models ought to be able to fit the data better.  The most intersting part is the increase in error variance as the models become more complex.  This also makes sense, because there are more quantities being estimated for each item.  For the 3PL, especially, estimates of the guessing parameter are particularly unstable with low to moderate numbers of respondents, so this feature also makes sense.

\section*{Consulting Excercise}


In the following plot, you can see comparisons of the ability estimates across the three models. Each of the models is almost perfectly correlated with one another. The scatter plots show the relationships among the ability estimates in each of the estimations. For each plot, the x-axis represents the estimate in that column, and the y-axis represents the estimate in that row. You can see that the scores given by the CTT model do not align perfectly with the ability estimates given by the Rasch and 3PL models, and that test-takers given the same sum score in the CTT model are sorted into different but nearly adjacent categories by the Rasch and 3PL models. Judging by the mostly tight scatter in the plot comparing the Rasch and 3PL models, the 3PL model does not change the ability estimates much of any but the lowest scorers from the Rasch model. The Rasch model abilities are slightly skewed, while the 3PL abilties show a more normal curve, which makes sense if some test-takers' abilities were lowered when taking into account guessing.

<<echo=FALSE, results='hide',message=FALSE>>=
##Ben's Code for Fancy Plots
resp<-read.table("https://raw.githubusercontent.com/ben-domingue/252L_winter2018/master/data/nde_math_white_space.txt",header=FALSE)

rowSums(resp,na.rm=TRUE)->ctt.est
#number of factors to extract
m1 <- mirt(resp,1)
rasch.est <- fscores(m1)[,1]
difs_rash <- extract.mirt(m1,'parvec')

m3 <- mirt(resp,itemtype="3PL",1)
three.est <- fscores(m3)[,1]
difs_3pl <- extract.mirt(m1,'parvec')

df <- data.frame(ctt.est,rasch.est,three.est)
pairs.panels(df,pch='.',gap=0)
@

<<results='hide'>>=
wrightMap(rasch.est,difs_rash, item.side = "itemClassic", main.title = "Wright Map: Rasch Model")
wrightMap(three.est,difs_3pl, item.side = "itemClassic", main.title = "Wright Map: 3PL")
@


<<echo=FALSE,fig.height=2.75>>=
data<-read.table("nde_math_white_space.txt")
score<-rowSums(data)
pv<-colMeans(data)
discrimination<-sapply(1:ncol(data), function(i) cor(score, data[, i], use='p')
)
par(mfrow=c(1,3))
plot(density(score))
plot(density(pv), xlim=c(0, 1))
plot(density(discrimination), xlim=c(0, 1))
@

<<echo=FASLE, results='hide', fig.cap="Standard error as a function of ability">>=
#generate models
mod1<-mirt(resp,1,itemtype="Rasch")
mod2<-mirt(resp,1,itemtype="2PL")
mod3<-mirt(resp,1,itemtype="3PL")

#estimate and sort abilities
fscores(mod1,full.scores.SE=TRUE)->th1
th1[order(th1[,1]),]->th1
fscores(mod2,full.scores.SE=TRUE)->th2
th2[order(th2[,1]),]->th2
fscores(mod3,full.scores.SE=TRUE)->th3
th3[order(th3[,1]),]->th3

#generate plots
par(mfrow=c(3,1))
plot(jitter(th1),xlab="theta",ylab="se", main='Rasch',xlim=c(-4,4))
plot(jitter(th2),xlab="theta",ylab="se",main='2PL',xlim=c(-4,4))
plot(jitter(th3),xlab="theta",ylab="se",main='3PL',xlim=c(-4,4))
@


<<echo=FASLE, results='hide', fig.cap="Test information by model">>=

#test information plots
par(mfrow=c(3,1))
plot(th1[,1],testinfo(mod1,th1[,1]),xlab='theta',ylab='information',main='Rasch')
plot(th2[,1],testinfo(mod2,th2[,1]),xlab='theta',ylab='information',main='2PL')
plot(th3[,1],testinfo(mod3,th3[,1]),xlab='theta',ylab='information',main='3PL')

<<echo=FALSE,results='hide',message=FALSE,fig.height=2.75>>=
#Rasch Model
mod1<-mirt(data,1,itemtype="Rasch")
rasch_fit <- itemfit(mod1,fit_stats='infit')
plot(density(rasch_fit[,2], main='Outfit'))
abline(v=1-1.96*.05,col='red')
abline(v=1+1.96*.05,col='red')
@


\end{enumerate}

\end{document}
